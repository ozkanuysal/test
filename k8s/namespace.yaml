
apiVersion: v1
kind: Namespace
metadata:
  name: ml-platform
  labels:
    name: ml-platform
    environment: production
    team: ml-engineering
---

apiVersion: v1
kind: ResourceQuota
metadata:
  name: ml-platform-quota
  namespace: ml-platform
spec:
  hard:
    # Compute resources
    requests.cpu: "200"                    # 200 cores total
    requests.memory: "500Gi"               # 500 GiB RAM total
    requests.nvidia.com/gpu: "160"         # 160 GPUs total (20 nodes Ã— 8)

    # Storage resources
    persistentvolumeclaims: "20"           # Max 20 PVCs
    requests.storage: "2Ti"                # Max 2 TiB total storage

    # Pods and services
    pods: "100"                            # Max 100 pods
    services: "20"                         # Max 20 services
    services.loadbalancers: "2"            # Max 2 load balancers

    # ConfigMaps and Secrets
    configmaps: "10"
    secrets: "10"
---

apiVersion: v1
kind: LimitRange
metadata:
  name: ml-platform-limits
  namespace: ml-platform
spec:
  limits:
  # Container-level limits
  - max:
      cpu: "32"                    # Max 32 cores per container
      memory: "128Gi"              # Max 128 GiB per container
      nvidia.com/gpu: "8"          # Max 8 GPUs per container
    min:
      cpu: "100m"                  # Min 0.1 core (100 millicores)
      memory: "128Mi"              # Min 128 MiB
    type: Container

  # Pod-level limits (sum of all containers)
  - max:
      cpu: "64"                    # Max 64 cores per pod
      memory: "256Gi"              # Max 256 GiB per pod
      nvidia.com/gpu: "8"          # Max 8 GPUs per pod
    type: Pod
