{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Features - Priority & Fair Share\n",
    "\n",
    "### Priority Queue\n",
    "- **HIGH**: Urgent jobs, production deadlines\n",
    "- **MEDIUM**: Standard training jobs (default)\n",
    "- **LOW**: Experiments, development work\n",
    "\n",
    "### Fair Share\n",
    "Prevents one user from using all GPUs:\n",
    "- Tracks GPU-hours per user\n",
    "- Limits users to 2× fair share\n",
    "- Example: 3 users → each gets ~33% of resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  Demo Mode: Code examples shown for educational purposes\n",
      "📦 In production, this requires Redis + Celery workers\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ozkanuysal/Desktop/test2/test/notebooks/../src/resources/gpu_manager.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-09 20:46:35 - root - \u001b[32mINFO\u001b[0m - Logging initialized at level INFO [logger.py:202]\n",
      "✓ Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "# Demo mode - these would connect to real Redis/Celery in production\n",
    "print(\"⚠️  Demo Mode: Code examples shown for educational purposes\")\n",
    "print(\"📦 In production, this requires Redis + Celery workers\\n\")\n",
    "\n",
    "from src.scheduler.job_queue import JobConfig, Priority\n",
    "from src.monitoring.logger import setup_logging\n",
    "import time\n",
    "\n",
    "setup_logging(level=\"INFO\")\n",
    "print(\"✓ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Priority Demonstration\n",
    "\n",
    "Submit 3 jobs with different priorities and watch queue ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-09 20:51:33 - src.scheduler.priority_manager - \u001b[33mWARNING\u001b[0m - Job low-priority-001 already in queue [priority_manager.py:116]\n",
      "2025-10-09 20:51:33 - src.scheduler.job_queue - \u001b[32mINFO\u001b[0m - Submitted job low-priority-001 to queue 'low_priority' (priority=LOW) [job_queue.py:340]\n",
      "✓ LOW priority job submitted (max 60s)\n",
      "2025-10-09 20:51:33 - src.scheduler.priority_manager - \u001b[33mWARNING\u001b[0m - Job medium-priority-001 already in queue [priority_manager.py:116]\n",
      "2025-10-09 20:51:33 - src.scheduler.job_queue - \u001b[32mINFO\u001b[0m - Submitted job medium-priority-001 to queue 'default' (priority=MEDIUM) [job_queue.py:340]\n",
      "✓ MEDIUM priority job submitted (max 60s)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 37\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m priority_name, priority_level \u001b[38;5;129;01min\u001b[39;00m priorities:\n\u001b[1;32m     31\u001b[0m     job \u001b[38;5;241m=\u001b[39m JobConfig(\n\u001b[1;32m     32\u001b[0m         job_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpriority_name\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-priority-001\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     33\u001b[0m         output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./output/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpriority_name\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     34\u001b[0m         priority\u001b[38;5;241m=\u001b[39mpriority_name,\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbase_config\n\u001b[1;32m     36\u001b[0m     )\n\u001b[0;32m---> 37\u001b[0m     \u001b[43mjob_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit_job\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpriority_level\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✓ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpriority_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m priority job submitted (max 60s)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/test2/test/notebooks/../src/scheduler/job_queue.py:318\u001b[0m, in \u001b[0;36mJobQueue.submit_job\u001b[0;34m(self, job_config, priority)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;124;03mSubmit a job to the queue\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03m    JobSubmissionError: If submission fails\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# Submit to priority manager\u001b[39;00m\n\u001b[0;32m--> 318\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpriority_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit_job\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpriority\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpriority\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimated_duration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimated_duration\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;66;03m# Store job config in Redis\u001b[39;00m\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_job_config(job_config)\n",
      "File \u001b[0;32m~/Desktop/test2/test/notebooks/../src/scheduler/priority_manager.py:144\u001b[0m, in \u001b[0;36mPriorityManager.submit_job\u001b[0;34m(self, job_id, user_id, num_gpus, priority, estimated_duration, metadata)\u001b[0m\n\u001b[1;32m    139\u001b[0m stats\u001b[38;5;241m.\u001b[39mtotal_jobs_submitted \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    140\u001b[0m stats\u001b[38;5;241m.\u001b[39mcurrent_queue_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    142\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSubmitted job \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (user=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, priority=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpriority\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpus=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_gpus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, queue_position=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_queue_position(job_id)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m )\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m job_request\n",
      "File \u001b[0;32m~/Desktop/test2/test/notebooks/../src/scheduler/priority_manager.py:381\u001b[0m, in \u001b[0;36mPriorityManager.get_queue_position\u001b[0;34m(self, job_id)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_queue_position\u001b[39m(\u001b[38;5;28mself\u001b[39m, job_id: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m    372\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    Get position of job in queue (1-indexed)\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;124;03m        Queue position or None if not in queue\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 381\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    382\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m job_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_job_index:\n\u001b[1;32m    383\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from src.scheduler.job_queue import get_job_queue\n",
    "from src.scheduler.priority_manager import get_priority_manager\n",
    "\n",
    "job_queue = get_job_queue()\n",
    "priority_manager = get_priority_manager()\n",
    "\n",
    "# Define base configuration with timeout\n",
    "base_config = {\n",
    "    \"user_id\": \"user-A\",\n",
    "    \"job_type\": \"fine_tuning\",\n",
    "    \"num_gpus\": 1,\n",
    "    \"pool_type\": \"development\",\n",
    "    \"is_preemptible\": True,\n",
    "    \"model_name\": \"distilbert-base-uncased\",\n",
    "    \"dataset_path\": \"./data/sample.csv\",\n",
    "    \"config\": {\n",
    "        \"max_steps\": 10,  # Reduced steps for faster completion\n",
    "        \"max_train_time\": 60,  # 60 seconds (1 minute) timeout\n",
    "        \"early_stopping\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "# Submit all jobs at once\n",
    "priorities = [\n",
    "    (\"LOW\", Priority.LOW),\n",
    "    (\"MEDIUM\", Priority.MEDIUM),\n",
    "    (\"HIGH\", Priority.HIGH)\n",
    "]\n",
    "\n",
    "for priority_name, priority_level in priorities:\n",
    "    job = JobConfig(\n",
    "        job_id=f\"{priority_name.lower()}-priority-001\",\n",
    "        output_dir=f\"./output/{priority_name.lower()}\",\n",
    "        priority=priority_name,\n",
    "        **base_config\n",
    "    )\n",
    "    job_queue.submit_job(job, priority_level)\n",
    "    print(f\"✓ {priority_name} priority job submitted (max 60s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Queue Positions (lower = runs first):\n",
      "  low-priority-001: Position 3\n",
      "  medium-priority-001: Position 2\n",
      "  high-priority-001: Position 1\n",
      "\n",
      "⚠️  Notice: HIGH priority job is position 1, even though submitted last!\n"
     ]
    }
   ],
   "source": [
    "# Check queue order\n",
    "print(\"\\nQueue Positions (lower = runs first):\")\n",
    "for job_id in [\"low-priority-001\", \"medium-priority-001\", \"high-priority-001\"]:\n",
    "    position = priority_manager.get_queue_position(job_id)\n",
    "    print(f\"  {job_id}: Position {position}\")\n",
    "\n",
    "print(\"\\n⚠️  Notice: HIGH priority job is position 1, even though submitted last!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fair Share Demo\n",
    "\n",
    "Simulate 3 users to show fair share in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Usage Recorded:\n",
      "  alice: 10.0 GPU-hours\n",
      "  bob: 10.0 GPU-hours\n",
      "  charlie: 50.0 GPU-hours\n"
     ]
    }
   ],
   "source": [
    "# Simulate GPU usage for 3 users\n",
    "users = [\"alice\", \"bob\", \"charlie\"]\n",
    "\n",
    "# Alice uses 10 GPU-hours\n",
    "priority_manager.record_job_completion(\n",
    "    job_id=\"alice-job-1\",\n",
    "    user_id=\"alice\",\n",
    "    num_gpus=2,\n",
    "    duration=18000  # 5 hours × 2 GPUs = 10 GPU-hours\n",
    ")\n",
    "\n",
    "# Bob uses 10 GPU-hours\n",
    "priority_manager.record_job_completion(\n",
    "    job_id=\"bob-job-1\",\n",
    "    user_id=\"bob\",\n",
    "    num_gpus=1,\n",
    "    duration=36000  # 10 hours × 1 GPU = 10 GPU-hours\n",
    ")\n",
    "\n",
    "# Charlie uses 50 GPU-hours (GREEDY!)\n",
    "priority_manager.record_job_completion(\n",
    "    job_id=\"charlie-job-1\",\n",
    "    user_id=\"charlie\",\n",
    "    num_gpus=4,\n",
    "    duration=45000  # 12.5 hours × 4 GPUs = 50 GPU-hours\n",
    ")\n",
    "\n",
    "print(\"GPU Usage Recorded:\")\n",
    "for user in users:\n",
    "    stats = priority_manager.get_user_stats(user)\n",
    "    if stats:\n",
    "        print(f\"  {user}: {stats.total_gpu_hours:.1f} GPU-hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total GPU-hours used: 70.0\n",
      "Fair share per user: 23.3 (33.3%)\n",
      "Max allowed (2× fair share): 46.7 (66.7%)\n",
      "\n",
      "  alice: 14.3% ✓ OK\n",
      "  bob: 14.3% ✓ OK\n",
      "  charlie: 71.4% ⚠️ OVER QUOTA\n",
      "\n",
      "⚠️  Charlie exceeded fair share! Next job may be delayed.\n"
     ]
    }
   ],
   "source": [
    "# Check fair share limits\n",
    "total_hours = sum(\n",
    "    priority_manager.get_user_stats(u).total_gpu_hours \n",
    "    for u in users if priority_manager.get_user_stats(u)\n",
    ")\n",
    "\n",
    "print(f\"\\nTotal GPU-hours used: {total_hours:.1f}\")\n",
    "print(f\"Fair share per user: {total_hours/3:.1f} (33.3%)\")\n",
    "print(f\"Max allowed (2× fair share): {total_hours/3*2:.1f} (66.7%)\\n\")\n",
    "\n",
    "for user in users:\n",
    "    stats = priority_manager.get_user_stats(user)\n",
    "    if stats:\n",
    "        share_pct = (stats.total_gpu_hours / total_hours) * 100\n",
    "        status = \"✓ OK\" if share_pct < 66.7 else \"⚠️ OVER QUOTA\"\n",
    "        print(f\"  {user}: {share_pct:.1f}% {status}\")\n",
    "\n",
    "print(\"\\n⚠️  Charlie exceeded fair share! Next job may be delayed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Starvation Prevention\n",
    "\n",
    "Jobs waiting too long (>1 hour) get priority boost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starvation Prevention:\n",
      "  Timeout: 3600s (1 hour)\n",
      "  Action: Boost priority to HIGH\n",
      "\n",
      "  Example:\n",
      "  - LOW priority job waits 65 minutes\n",
      "  - System auto-boosts to HIGH priority\n",
      "  - Job moves to front of queue\n",
      "  - Prevents indefinite waiting\n"
     ]
    }
   ],
   "source": [
    "# Check starvation timeout\n",
    "starvation_timeout = 3600  # 1 hour default\n",
    "\n",
    "print(f\"Starvation Prevention:\")\n",
    "print(f\"  Timeout: {starvation_timeout}s (1 hour)\")\n",
    "print(f\"  Action: Boost priority to HIGH\")\n",
    "print(f\"\\n  Example:\")\n",
    "print(f\"  - LOW priority job waits 65 minutes\")\n",
    "print(f\"  - System auto-boosts to HIGH priority\")\n",
    "print(f\"  - Job moves to front of queue\")\n",
    "print(f\"  - Prevents indefinite waiting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Queue Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queue Summary:\n",
      "  Total jobs: 3\n",
      "  Unique users: 1\n",
      "  Total GPUs requested: 3\n",
      "  Oldest job wait time: 539s\n",
      "\n",
      "Priority Breakdown:\n",
      "  HIGH: 1 jobs\n",
      "  MEDIUM: 1 jobs\n",
      "  LOW: 1 jobs\n"
     ]
    }
   ],
   "source": [
    "# Get queue summary\n",
    "summary = priority_manager.get_queue_summary()\n",
    "\n",
    "print(\"Queue Summary:\")\n",
    "print(f\"  Total jobs: {summary['total_jobs']}\")\n",
    "print(f\"  Unique users: {summary['unique_users']}\")\n",
    "print(f\"  Total GPUs requested: {summary['total_requested_gpus']}\")\n",
    "print(f\"  Oldest job wait time: {summary['oldest_job_wait_time']:.0f}s\\n\")\n",
    "\n",
    "print(\"Priority Breakdown:\")\n",
    "for priority, count in summary['priority_breakdown'].items():\n",
    "    print(f\"  {priority}: {count} jobs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-09 20:56:11 - src.scheduler.priority_manager - \u001b[32mINFO\u001b[0m - Cancelled job low-priority-001 [priority_manager.py:339]\n",
      "✓ Job cancelled successfully\n",
      "  Job removed from queue\n",
      "  Resources freed for other jobs\n"
     ]
    }
   ],
   "source": [
    "# Cancel a job\n",
    "cancelled = priority_manager.cancel_job(\"low-priority-001\")\n",
    "\n",
    "if cancelled:\n",
    "    print(\"✓ Job cancelled successfully\")\n",
    "    print(\"  Job removed from queue\")\n",
    "    print(\"  Resources freed for other jobs\")\n",
    "else:\n",
    "    print(\"✗ Job not found or already running\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Custom Fair Share Quotas\n",
    "\n",
    "Set different quotas for different users/teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-09 20:56:19 - src.scheduler.priority_manager - \u001b[32mINFO\u001b[0m - Set fair share quota for user premium-user: 2.0 [priority_manager.py:447]\n",
      "2025-10-09 20:56:19 - src.scheduler.priority_manager - \u001b[32mINFO\u001b[0m - Set fair share quota for user research-team: 1.5 [priority_manager.py:447]\n",
      "2025-10-09 20:56:19 - src.scheduler.priority_manager - \u001b[32mINFO\u001b[0m - Set fair share quota for user free-tier: 0.5 [priority_manager.py:447]\n",
      "Custom Quotas Set:\n",
      "  premium-user: 2.0× (gets 2× normal share)\n",
      "  research-team: 1.5× (gets 1.5× normal share)\n",
      "  free-tier: 0.5× (gets half normal share)\n",
      "\n",
      "  Example with 100 GPU-hours available:\n",
      "  - premium-user can use up to 50 hours\n",
      "  - research-team can use up to 37.5 hours\n",
      "  - free-tier can use up to 12.5 hours\n"
     ]
    }
   ],
   "source": [
    "# Set custom quotas\n",
    "# Default quota = 1.0 (equal share)\n",
    "\n",
    "# Premium user gets 2× resources\n",
    "priority_manager.set_user_fair_share(\"premium-user\", quota=2.0)\n",
    "\n",
    "# Research team gets 1.5× resources  \n",
    "priority_manager.set_user_fair_share(\"research-team\", quota=1.5)\n",
    "\n",
    "# Free tier gets 0.5× resources\n",
    "priority_manager.set_user_fair_share(\"free-tier\", quota=0.5)\n",
    "\n",
    "print(\"Custom Quotas Set:\")\n",
    "print(f\"  premium-user: 2.0× (gets 2× normal share)\")\n",
    "print(f\"  research-team: 1.5× (gets 1.5× normal share)\")\n",
    "print(f\"  free-tier: 0.5× (gets half normal share)\")\n",
    "print(f\"\\n  Example with 100 GPU-hours available:\")\n",
    "print(f\"  - premium-user can use up to 50 hours\")\n",
    "print(f\"  - research-team can use up to 37.5 hours\")\n",
    "print(f\"  - free-tier can use up to 12.5 hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Real-World Scenarios\n",
    "\n",
    "### Scenario 1: Production Deadline\n",
    "\n",
    "```python\n",
    "# Urgent production model needs HIGH priority\n",
    "urgent_job = JobConfig(\n",
    "    job_id=\"prod-urgent-001\",\n",
    "    priority=\"HIGH\",\n",
    "    is_preemptible=False,  # Don't interrupt\n",
    "    pool_type=\"production\"\n",
    ")\n",
    "job_queue.submit_job(urgent_job, Priority.HIGH)\n",
    "# → Goes to front of queue immediately\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
