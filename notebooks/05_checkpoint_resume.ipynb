{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Checkpoint & Resume - Fault Tolerance\n",
        "\n",
        "## Why Checkpointing?\n",
        "\n",
        "### Without Checkpoints\n",
        "```\n",
        "Job runs 8 hours ‚Üí GPU fails at 7.5 hours ‚Üí LOSE EVERYTHING ‚ùå\n",
        "Restart from scratch ‚Üí Another 8 hours ‚Üí 16 hours total üò¢\n",
        "```\n",
        "\n",
        "### With Checkpoints (every 30 min)\n",
        "```\n",
        "Job runs 8 hours ‚Üí GPU fails at 7.5 hours ‚Üí Checkpoint at 7.0 hours ‚úì\n",
        "Resume from 7.0 hours ‚Üí 1 hour to finish ‚Üí 9 hours total üéâ\n",
        "Saved: 7 hours (44% time savings)\n",
        "```\n",
        "\n",
        "## Checkpoint Contents\n",
        "\n",
        "A checkpoint saves:\n",
        "- ‚úÖ **Model weights** (state_dict)\n",
        "- ‚úÖ **Optimizer state** (momentum, lr)\n",
        "- ‚úÖ **Training step** (epoch, global_step)\n",
        "- ‚úÖ **Random state** (reproducibility)\n",
        "- ‚úÖ **Best metrics** (accuracy, loss)\n",
        "- ‚úÖ **Scheduler state** (learning rate schedule)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-10-09 21:21:15 - root - \u001b[32mINFO\u001b[0m - Logging initialized at level INFO [logger.py:202]\n",
            "‚úì Setup complete!\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '..')\n",
        "\n",
        "from src.pipeline.checkpoint_manager import CheckpointManager\n",
        "from src.scheduler.job_queue import JobConfig, get_job_queue, Priority\n",
        "from src.monitoring.logger import setup_logging\n",
        "\n",
        "setup_logging(level=\"INFO\")\n",
        "print(\"‚úì Setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Checkpoint Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-10-09 21:30:18 - src.pipeline.checkpoint_manager - \u001b[32mINFO\u001b[0m - Checkpoint manager initialized: ./checkpoints/demo_job (max=3, best_only=False) [checkpoint_manager.py:52]\n",
            "Checkpoint Configuration:\n",
            "  Directory: checkpoints/demo_job\n",
            "  Max checkpoints: 3\n",
            "  Save best only: False\n"
          ]
        }
      ],
      "source": [
        "# Configure checkpoint strategy\n",
        "checkpoint_manager = CheckpointManager(\n",
        "    checkpoint_dir=\"./checkpoints/demo_job\",\n",
        "    max_checkpoints=3,  # Keep last 3\n",
        "    save_best_only=False  # Save all checkpoints\n",
        ")\n",
        "\n",
        "print(\"Checkpoint Configuration:\")\n",
        "print(f\"  Directory: {checkpoint_manager.checkpoint_dir}\")\n",
        "print(f\"  Max checkpoints: {checkpoint_manager.max_checkpoints}\")\n",
        "print(f\"  Save best only: {checkpoint_manager.save_best_only}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Create Checkpoint Manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-10-09 21:23:24 - src.pipeline.checkpoint_manager - \u001b[32mINFO\u001b[0m - Checkpoint manager initialized: ./checkpoints/demo_job (max=3, best_only=False) [checkpoint_manager.py:52]\n",
            "Checkpoint Manager Initialized\n",
            "  Checkpoint directory: checkpoints/demo_job\n",
            "‚úì Checkpoint directory ready\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Initialize checkpoint manager\n",
        "checkpoint_manager = CheckpointManager(\n",
        "    checkpoint_dir=\"./checkpoints/demo_job\",\n",
        "    max_checkpoints=3,\n",
        "    save_best_only=False\n",
        ")\n",
        "\n",
        "print(f\"Checkpoint Manager Initialized\")\n",
        "print(f\"  Checkpoint directory: {checkpoint_manager.checkpoint_dir}\")\n",
        "\n",
        "# Checkpoint directory already created by CheckpointManager.__init__\n",
        "print(f\"‚úì Checkpoint directory ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Saving Checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-10-09 21:24:30 - src.pipeline.checkpoint_manager - \u001b[32mINFO\u001b[0m - Saving checkpoint to checkpoints/demo_job/checkpoint_epoch1_step1000 [checkpoint_manager.py:96]\n",
            "2025-10-09 21:24:30 - src.pipeline.checkpoint_manager - \u001b[32mINFO\u001b[0m - New best checkpoint: checkpoints/demo_job/checkpoint_epoch1_step1000 (metric=0.1890) [checkpoint_manager.py:134]\n",
            "2025-10-09 21:24:30 - src.pipeline.checkpoint_manager - \u001b[32mINFO\u001b[0m - Checkpoint saved: checkpoints/demo_job/checkpoint_epoch1_step1000 [checkpoint_manager.py:139]\n",
            "‚úì Checkpoint saved: checkpoints/demo_job/checkpoint_epoch1_step1000\n",
            "  Epoch: 1, Step: 1000\n",
            "  Eval loss: 0.189\n",
            "  Eval accuracy: 92%\n"
          ]
        }
      ],
      "source": [
        "# Simulate training and save checkpoints\n",
        "import torch\n",
        "\n",
        "# Create dummy model and optimizer (for demo)\n",
        "model = torch.nn.Linear(10, 2)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Save checkpoint\n",
        "checkpoint_path = checkpoint_manager.save_checkpoint(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    epoch=1,\n",
        "    step=1000,\n",
        "    metrics={\"eval_loss\": 0.189, \"eval_accuracy\": 0.92},\n",
        "    train_loss=0.234,\n",
        "    best_metric=0.189\n",
        ")\n",
        "\n",
        "if checkpoint_path:\n",
        "    print(f\"‚úì Checkpoint saved: {checkpoint_path}\")\n",
        "    print(f\"  Epoch: 1, Step: 1000\")\n",
        "    print(f\"  Eval loss: 0.189\")\n",
        "    print(f\"  Eval accuracy: 92%\")\n",
        "else:\n",
        "    print(\"‚úì Checkpoint skipped (not better than previous)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-10-09 21:25:15 - src.pipeline.checkpoint_manager - \u001b[32mINFO\u001b[0m - Saving checkpoint to checkpoints/demo_job/checkpoint_epoch2_step2000 [checkpoint_manager.py:96]\n",
            "2025-10-09 21:25:15 - src.pipeline.checkpoint_manager - \u001b[32mINFO\u001b[0m - Checkpoint saved: checkpoints/demo_job/checkpoint_epoch2_step2000 [checkpoint_manager.py:139]\n",
            "Checkpoint saved - Epoch 2, Step 2000: loss=0.473\n",
            "2025-10-09 21:25:15 - src.pipeline.checkpoint_manager - \u001b[32mINFO\u001b[0m - Saving checkpoint to checkpoints/demo_job/checkpoint_epoch3_step3000 [checkpoint_manager.py:96]\n",
            "2025-10-09 21:25:15 - src.pipeline.checkpoint_manager - \u001b[32mINFO\u001b[0m - Checkpoint saved: checkpoints/demo_job/checkpoint_epoch3_step3000 [checkpoint_manager.py:139]\n",
            "Checkpoint saved - Epoch 3, Step 3000: loss=0.315\n",
            "2025-10-09 21:25:15 - src.pipeline.checkpoint_manager - \u001b[32mINFO\u001b[0m - Saving checkpoint to checkpoints/demo_job/checkpoint_epoch4_step4000 [checkpoint_manager.py:96]\n",
            "2025-10-09 21:25:15 - src.pipeline.checkpoint_manager - \u001b[32mINFO\u001b[0m - Checkpoint saved: checkpoints/demo_job/checkpoint_epoch4_step4000 [checkpoint_manager.py:139]\n",
            "Checkpoint saved - Epoch 4, Step 4000: loss=0.236\n",
            "2025-10-09 21:25:15 - src.pipeline.checkpoint_manager - \u001b[32mINFO\u001b[0m - Saving checkpoint to checkpoints/demo_job/checkpoint_epoch5_step5000 [checkpoint_manager.py:96]\n",
            "2025-10-09 21:25:15 - src.pipeline.checkpoint_manager - \u001b[32mINFO\u001b[0m - Removed old checkpoint: checkpoints/demo_job/checkpoint_epoch2_step2000 [checkpoint_manager.py:257]\n",
            "2025-10-09 21:25:16 - src.pipeline.checkpoint_manager - \u001b[32mINFO\u001b[0m - Checkpoint saved: checkpoints/demo_job/checkpoint_epoch5_step5000 [checkpoint_manager.py:139]\n",
            "Checkpoint saved - Epoch 5, Step 5000: loss=0.189\n",
            "\n",
            "‚úì Multiple checkpoints saved\n"
          ]
        }
      ],
      "source": [
        "# Save multiple checkpoints (simulating training progress)\n",
        "for epoch, step in enumerate([2000, 3000, 4000, 5000], start=2):\n",
        "    eval_loss = 0.189 * (5000 / step)  # Decreasing loss\n",
        "    \n",
        "    checkpoint_path = checkpoint_manager.save_checkpoint(\n",
        "        model=model,\n",
        "        optimizer=optimizer,\n",
        "        epoch=epoch,\n",
        "        step=step,\n",
        "        metrics={\"eval_loss\": eval_loss}\n",
        "    )\n",
        "    \n",
        "    if checkpoint_path:\n",
        "        print(f\"Checkpoint saved - Epoch {epoch}, Step {step}: loss={eval_loss:.3f}\")\n",
        "\n",
        "print(\"\\n‚úì Multiple checkpoints saved\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. List Available Checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available Checkpoints (3):\n",
            "  {'path': 'checkpoints/demo_job/checkpoint_epoch3_step3000', 'epoch': 3, 'step': 3000, 'metrics': {'eval_loss': 0.315}}\n",
            "  {'path': 'checkpoints/demo_job/checkpoint_epoch4_step4000', 'epoch': 4, 'step': 4000, 'metrics': {'eval_loss': 0.23625000000000002}}\n",
            "  {'path': 'checkpoints/demo_job/checkpoint_epoch5_step5000', 'epoch': 5, 'step': 5000, 'metrics': {'eval_loss': 0.189}}\n",
            "\n",
            "Best checkpoint: checkpoints/demo_job/checkpoint_epoch1_step1000\n",
            "Has checkpoints: True\n"
          ]
        }
      ],
      "source": [
        "# Get all checkpoints\n",
        "checkpoints = checkpoint_manager.list_checkpoints()\n",
        "\n",
        "print(f\"Available Checkpoints ({len(checkpoints)}):\")\n",
        "for ckpt_path in checkpoints:\n",
        "    print(f\"  {ckpt_path}\")\n",
        "\n",
        "# Get best checkpoint path\n",
        "best_path = checkpoint_manager.get_best_checkpoint_path()\n",
        "if best_path:\n",
        "    print(f\"\\nBest checkpoint: {best_path}\")\n",
        "else:\n",
        "    print(\"\\nNo best checkpoint tracked\")\n",
        "\n",
        "# Check if checkpoints exist\n",
        "has_ckpt = checkpoint_manager.has_checkpoint()\n",
        "print(f\"Has checkpoints: {has_ckpt}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Resume from Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Simulating job crash and resume...\n",
            "\n",
            "Before resume:\n",
            "  Model state: random initialization\n",
            "  Global step: 0\n",
            "\n",
            "2025-10-09 21:27:36 - src.pipeline.checkpoint_manager - \u001b[32mINFO\u001b[0m - Loading checkpoint from checkpoints/demo_job/checkpoint_epoch5_step5000 [checkpoint_manager.py:186]\n",
            "2025-10-09 21:27:36 - src.pipeline.checkpoint_manager - \u001b[32mINFO\u001b[0m - Checkpoint loaded: epoch=5, step=5000 [checkpoint_manager.py:212]\n",
            "After resume:\n",
            "  Model state: restored from checkpoint\n",
            "  Global step: 5000\n",
            "  Epoch: 5\n",
            "  Training continues from step 5001\n",
            "\n",
            "‚úì Training resumed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Load checkpoint to resume training\n",
        "print(\"Simulating job crash and resume...\\n\")\n",
        "\n",
        "# Create fresh model and optimizer (simulating restart)\n",
        "new_model = torch.nn.Linear(10, 2)\n",
        "new_optimizer = torch.optim.Adam(new_model.parameters(), lr=1e-4)\n",
        "\n",
        "print(\"Before resume:\")\n",
        "print(f\"  Model state: random initialization\")\n",
        "print(f\"  Global step: 0\")\n",
        "print()\n",
        "\n",
        "# Load checkpoint (pass model and optimizer to load state into them)\n",
        "metadata = checkpoint_manager.load_checkpoint(\n",
        "    model=new_model,\n",
        "    optimizer=new_optimizer,\n",
        "    load_best=False  # Load latest checkpoint\n",
        ")\n",
        "\n",
        "# Get restored state from metadata\n",
        "start_step = metadata.get(\"step\", 0)\n",
        "start_epoch = metadata.get(\"epoch\", 0)\n",
        "\n",
        "print(\"After resume:\")\n",
        "print(f\"  Model state: restored from checkpoint\")\n",
        "print(f\"  Global step: {start_step}\")\n",
        "print(f\"  Epoch: {start_epoch}\")\n",
        "print(f\"  Training continues from step {start_step + 1}\")\n",
        "print()\n",
        "print(\"‚úì Training resumed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Job Configuration with Checkpointing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Job Configuration with Checkpointing:\n",
            "  Save checkpoints every: 500 steps\n",
            "  Keep checkpoints: 3\n",
            "  Auto-resume: True\n",
            "  Load best at end: True\n"
          ]
        }
      ],
      "source": [
        "# Job config with checkpoint settings\n",
        "job_with_checkpoints = JobConfig(\n",
        "    job_id=\"checkpoint-demo-001\",\n",
        "    user_id=\"demo-user\",\n",
        "    job_type=\"fine_tuning\",\n",
        "    \n",
        "    pool_type=\"production\",\n",
        "    num_gpus=1,\n",
        "    is_preemptible=False,\n",
        "    \n",
        "    model_name=\"bert-base-uncased\",\n",
        "    dataset_path=\"./data/train.csv\",\n",
        "    output_dir=\"./output/checkpoint_demo\",\n",
        "    \n",
        "    priority=\"MEDIUM\",\n",
        "    estimated_duration=3600,\n",
        "    \n",
        "    config={\n",
        "        # Checkpointing\n",
        "        \"checkpoint_dir\": \"./checkpoints/checkpoint_demo\",\n",
        "        \"save_steps\": 500,  # Every 500 steps\n",
        "        \"save_total_limit\": 3,  # Keep 3 checkpoints\n",
        "        \"save_strategy\": \"steps\",  # \"steps\" or \"epoch\"\n",
        "        \n",
        "        # Resume settings\n",
        "        \"resume_from_checkpoint\": True,  # Auto-resume if checkpoint exists\n",
        "        \"ignore_data_skip\": False,  # Skip already processed data\n",
        "        \n",
        "        # Evaluation\n",
        "        \"evaluation_strategy\": \"steps\",\n",
        "        \"eval_steps\": 500,\n",
        "        \"load_best_model_at_end\": True,  # Load best checkpoint when done\n",
        "        \"metric_for_best_model\": \"eval_loss\",\n",
        "        \n",
        "        # Training\n",
        "        \"num_train_epochs\": 3,\n",
        "        \"per_device_train_batch_size\": 16,\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"Job Configuration with Checkpointing:\")\n",
        "print(f\"  Save checkpoints every: {job_with_checkpoints.config['save_steps']} steps\")\n",
        "print(f\"  Keep checkpoints: {job_with_checkpoints.config['save_total_limit']}\")\n",
        "print(f\"  Auto-resume: {job_with_checkpoints.config['resume_from_checkpoint']}\")\n",
        "print(f\"  Load best at end: {job_with_checkpoints.config['load_best_model_at_end']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Checkpoint Management"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint Management:\n",
            "\n",
            "Total checkpoints: 3\n",
            "Max checkpoints setting: 3\n",
            "Remaining checkpoints: 3\n",
            "\n",
            "Storage used: 0.01 MB\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Cleanup old checkpoints\n",
        "print(\"Checkpoint Management:\\n\")\n",
        "\n",
        "# List checkpoints\n",
        "checkpoints = checkpoint_manager.list_checkpoints()\n",
        "print(f\"Total checkpoints: {len(checkpoints)}\")\n",
        "\n",
        "# Cleanup is automatic (called by save_checkpoint)\n",
        "# But you can check max_checkpoints setting\n",
        "print(f\"Max checkpoints setting: {checkpoint_manager.max_checkpoints}\")\n",
        "print(f\"Remaining checkpoints: {len(checkpoints)}\\n\")\n",
        "\n",
        "# Calculate storage used\n",
        "total_size = 0\n",
        "for ckpt in checkpoints:\n",
        "    ckpt_path = Path(ckpt['path'])\n",
        "    if ckpt_path.exists():\n",
        "        # Calculate directory size\n",
        "        total_size += sum(f.stat().st_size for f in ckpt_path.rglob('*') if f.is_file())\n",
        "\n",
        "print(f\"Storage used: {total_size / (1024**2):.2f} MB\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
